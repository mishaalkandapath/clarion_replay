{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TEST_GRIDS = {}\n",
    "def read_h5py_string(dataset):\n",
    "    refs = dataset[()][0]  # Unpack the array of object references\n",
    "    strings = []\n",
    "    for ref in refs:\n",
    "        obj = dataset.file[ref]\n",
    "        string = obj[()].tobytes().decode(\"utf-16\")  # Decode the byte string\n",
    "        strings.append(string)\n",
    "    return strings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data_perparticipant(participant_num):\n",
    "    session_files = sorted(glob.glob(f\"/Users/mishaal/personalproj/clarion_replay/raw/Behav/s{participant_num}/T*.mat\"))\n",
    "    num_sessions = len(session_files)\n",
    "    meg_data = h5py.File(f\"/Users/mishaal/personalproj/clarion_replay/raw/data/s{participant_num}/Data_inference.mat\")\n",
    "    classifier_data = h5py.File(f\"/Users/mishaal/personalproj/clarion_replay/raw/data/s{participant_num}/Class_data.mat\")\n",
    "    \n",
    "    meg_signal_data = np.transpose(meg_data[\"data\"], (2, 1, 0))\n",
    "    meg_correct_dup = np.array(meg_data[\"correct_trials_all\"]).T\n",
    "    bricks_conn_trial = np.array(meg_data[\"bricks_conn_trial\"]).T\n",
    "    bricks_rel_trial = np.array(meg_data[\"bricks_rel_trial\"]).T\n",
    "    stim_labels = read_h5py_string(meg_data[\"stimlabel\"])# each unique presentation of a grid is given a label\n",
    "\n",
    "    assert num_sessions * 48 == bricks_conn_trial.shape[0], f\"mismatch in trial numbers for participant {participant_num} {num_sessions * 48} {bricks_conn_trial.shape[0]}\"\n",
    "    #load the binomial classifiers \n",
    "    betas = np.array(classifier_data[\"betas_loc\"]).T\n",
    "    intercepts = np.array(classifier_data[\"intercepts_loc\"]).T\n",
    "\n",
    "    os.makedirs(f\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/s{participant_num}\", exist_ok=True)\n",
    "    os.makedirs(f\"/Users/mishaal/personalproj/clarion_replay/processed/train_data/s{participant_num}\", exist_ok=True)\n",
    "\n",
    "    p_df = {\"PID\":[int(participant_num)]*bricks_conn_trial.shape[0], \n",
    "            \"Session\": [], \"Trial\": [], \"Grid_Name\": [],\n",
    "            \"left_element\": [], \"ontop_element\": [], \"right_element\": [], \"below_element\": [],\n",
    "            \"besideness\": [], \"middle\": [], \"ontopness\": [], \n",
    "              \"Q_Brick_Middle\": [], \"Q_Brick_Left\": [], \"Q_Relation\": [], \"True Relation\": [], \"Correct\": [], \"RT\":[]}\n",
    "\n",
    "    absolute_trial_index = 0\n",
    "    for idx, filename in enumerate(session_files):\n",
    "        all_data = loadmat(filename)\n",
    "        behav_data = all_data[\"res\"][0, 0][\"behav\"][0,0]\n",
    "        stimulus_grids = behav_data[\"SOLUTIONS_BUILT\"]\n",
    "        correctness = behav_data[\"correct\"]\n",
    "        rts = behav_data[\"rt\"]\n",
    "        q_stimuli = behav_data[\"stim_catch\"]\n",
    "        query_relation = behav_data[\"question_catch\"] # a brick is presented in the middle and another on the top left corner. the relation of the top left brick to the middle brick is asked. This is the identity of the brick in the top left corner\n",
    "        true_relation = behav_data[\"relation_catch\"] # the relation in question\n",
    "\n",
    "        # save experiment data\n",
    "        n_trials = correctness.shape[1]\n",
    "        p_df[\"Session\"].extend([idx+1]*n_trials)\n",
    "        p_df[\"Trial\"].extend(list(range(1, n_trials+1)))\n",
    "        # turns out labeling not unique?\n",
    "        # stim_label = stim_labels[absolute_trial_index: absolute_trial_index + n_trials]\n",
    "        # p_df[\"Grid_Name\"].extend(stim_label)\n",
    "\n",
    "        p_df[\"left_element\"].extend([bricks_rel_trial[i, 0] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "        p_df[\"ontop_element\"].extend([bricks_rel_trial[i, 1] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "        p_df[\"right_element\"].extend([bricks_rel_trial[i, 2] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "        p_df[\"below_element\"].extend([bricks_rel_trial[i, 3] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "\n",
    "        p_df[\"besideness\"].extend([bricks_conn_trial[i, 0] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "        p_df[\"middle\"].extend([bricks_conn_trial[i, 1] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "        p_df[\"ontopness\"].extend([bricks_conn_trial[i, 2] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "\n",
    "        p_df[\"Q_Brick_Left\"].extend(q_stimuli[:, 0].flatten())\n",
    "        p_df[\"Q_Brick_Middle\"].extend(q_stimuli[:, 1].flatten())\n",
    "        p_df[\"Q_Relation\"].extend(query_relation.flatten())\n",
    "        p_df[\"True Relation\"].extend(true_relation.flatten())\n",
    "\n",
    "        p_df[\"Correct\"].extend(correctness.flatten())\n",
    "        p_df[\"RT\"].extend(rts.flatten())\n",
    "\n",
    "        for j in range(n_trials): # add the grid\n",
    "            t = 0\n",
    "            for grid in ALL_TEST_GRIDS:\n",
    "                if np.all(ALL_TEST_GRIDS[grid] == stimulus_grids[:, :, j]):\n",
    "                    t = 1\n",
    "                    p_df[\"Grid_Name\"].append(grid)\n",
    "                    break\n",
    "            if t == 0: \n",
    "                ALL_TEST_GRIDS[f\"GRID{len(ALL_TEST_GRIDS)}\"] = stimulus_grids[:, :, j]\n",
    "                p_df[\"Grid_Name\"].append(f\"GRID{len(ALL_TEST_GRIDS)-1}\")\n",
    "\n",
    "        absolute_trial_index += n_trials\n",
    "\n",
    "    #Save MEG data\n",
    "    np.save(f\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/s{participant_num}/meg_data.npy\", meg_signal_data)\n",
    "    #save classifier data\n",
    "    np.save(f\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/s{participant_num}/classifier_coeffs.npy\", betas)    \n",
    "    np.save(f\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/s{participant_num}/classifier_intercepts.npy\", intercepts)\n",
    "    assert np.all(meg_correct_dup.flatten() == np.array(p_df[\"Correct\"])), f\"correctness mismatch for participant {participant_num}\"  \n",
    "\n",
    "    p_df = pd.DataFrame(p_df)\n",
    "    p_df.to_csv(f\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/s{participant_num}/test_data.csv\")\n",
    "\n",
    "    return p_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = glob.glob(\"/Users/mishaal/personalproj/clarion_replay/raw/Behav/s*\")\n",
    "participants = sorted([(p.split(\"/\")[-1][1:]) for p in participants])\n",
    "dfs = []\n",
    "for p in tqdm(participants):\n",
    "    p_df = load_test_data_perparticipant(p)\n",
    "    dfs.append(p_df)\n",
    "\n",
    "# concatenate dataframes\n",
    "pd.concat(dfs).to_csv(\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/all_test_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tapnseek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
