{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TEST_GRIDS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: valid expression required before '}' (3970785379.py, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 62\u001b[0;36m\u001b[0m\n\u001b[0;31m    assert np.all(ALL_TEST_GRIDS[stim_label[absolute_trial_index + j]] == stimulus_grids[:, :, j]), f\"Grids don't match participant {}, session {}, trial {}\".format(participant_num, idx+1, j+1)\u001b[0m\n\u001b[0m                                                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: valid expression required before '}'\n"
     ]
    }
   ],
   "source": [
    "def load_test_data_perparticipant(participant_num):\n",
    "    session_files = glob.glob(f\"/Users/mishaal/personalproj/Generative-Replay/MEG_Behav/s{participant_num}/T*.mat\")\n",
    "    num_sessions = len(session_files)\n",
    "    meg_data = loadmat(f\"/Users/mishaal/personalproj/Generative-Replay/MEG_data/s{participant_num}/Data_inference.mat\")\n",
    "    classifier_data = loadmat(f\"/Users/mishaal/personalproj/Generative-Replay/MEG_data/s{participant_num}/Class_data.mat\")\n",
    "    \n",
    "    meg_signal_data = meg_data[\"data\"]\n",
    "    meg_correct_dup = meg_data[\"correct_trials_all\"]\n",
    "    bricks_conn_trial = meg_data[\"bricks_conn_trial\"]\n",
    "    bricks_rel_trial = meg_data[\"bricks_rel_trial\"]\n",
    "    stim_labels = meg_data[\"stimlabel\"]# each unique presentation of a grid is given a label\n",
    "\n",
    "    assert num_sessions * 48 == bricks_conn_trial.shape[0], \"mismatch in trial numbers for participant %d\" % participant_num\n",
    "\n",
    "    #load the binomial classifiers \n",
    "    betas = classifier_data[\"betas_loc\"]\n",
    "    intercepts = classifier_data[\"intercepts_loc\"]\n",
    "\n",
    "    os.makedirs(f\"/Users/mishaal/personalproj/clarion_replay/data/test_data/s{participant_num}\", exist_ok=True)\n",
    "    os.makedirs(f\"/Users/mishaal/personalproj/clarion_replay/data/train_data/s{participant_num}\", exist_ok=True)\n",
    "\n",
    "    p_df = {\"PID\":[int(participant_num)]*bricks_conn_trial.shape[0], \n",
    "            \"Session\": [], \"Trial\": [], \"Grid_Name\": [],\n",
    "            \"left_element\": [], \"ontop_element\": [], \"right_element\": [], \"below_element\": [],\n",
    "            \"besideness\": [], \"middle\": [], \"ontopness\": [], \n",
    "              \"Q_Brick_Middle\": [], \"Q_Brick_Left\": [], \"Q_Relation\": [], \"True Relation\": [], \"Correct\": [], \"RT\":[]}\n",
    "\n",
    "    absolute_trial_index = 0\n",
    "    for idx, filename in enumerate(session_files):\n",
    "        all_data = loadmat(filename)\n",
    "        behav_data = all_data[\"res\"][0, 0][\"behav\"][0,0]\n",
    "        stimulus_grids = behav_data[\"SOLUTIONS_BUILT\"]\n",
    "        correctness = behav_data[\"correct\"]\n",
    "        rts = behav_data[\"rt\"]\n",
    "        q_stimuli = behav_data[\"stim_catch\"]\n",
    "        query_relation = behav_data[\"question_catch\"] # a brick is presented in the middle and another on the top left corner. the relation of the top left brick to the middle brick is asked. This is the identity of the brick in the top left corner\n",
    "        true_relation = behav_data[\"relation_catch\"] # the relation in question\n",
    "        \n",
    "        # save experiment data\n",
    "        n_trials = correctness.shape[0]\n",
    "        p_df[\"Session\"].extend([idx+1]*n_trials)\n",
    "        p_df[\"Trial\"].extend(list(range(1, n_trials+1)))\n",
    "        stim_label = stim_labels[absolute_trial_index: absolute_trial_index + n_trials]\n",
    "        p_df[\"Grid_Name\"].extend(stim_label)\n",
    "\n",
    "        p_df[\"left_element\"].extend([bricks_rel_trial[i, 0] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "        p_df[\"ontop_element\"].extend([bricks_rel_trial[i, 1] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "        p_df[\"right_element\"].extend([bricks_rel_trial[i, 2] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "        p_df[\"below_element\"].extend([bricks_rel_trial[i, 3] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "\n",
    "        p_df[\"besideness\"].extend([bricks_conn_trial[i, 0] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "        p_df[\"middle\"].extend([bricks_conn_trial[i, 1] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "        p_df[\"ontopness\"].extend([bricks_conn_trial[i, 2] for i in range(absolute_trial_index, absolute_trial_index + n_trials)])\n",
    "\n",
    "        p_df[\"Q_Brick_Left\"].extend(q_stimuli[:, 0].flatten())\n",
    "        p_df[\"Q_Brick_Middle\"].extend(q_stimuli[:, 1].flatten())\n",
    "        p_df[\"Q_Relation\"].extend(query_relation)\n",
    "        p_df[\"True Relation\"].extend(true_relation)\n",
    "\n",
    "        p_df[\"Correct\"].extend(correctness.flatten())\n",
    "        p_df[\"RT\"].extend(rts.flatten())\n",
    "\n",
    "        for j in range(n_trials): # add the grid\n",
    "            if stim_label[absolute_trial_index + j] not in ALL_TEST_GRIDS:\n",
    "                ALL_TEST_GRIDS[stim_label[absolute_trial_index + j]] = stimulus_grids[:, :, j]\n",
    "            else:\n",
    "                assert np.all(ALL_TEST_GRIDS[stim_label[absolute_trial_index + j]] == stimulus_grids[:, :, j]), f\"Grids don't match participant {}, session {}, trial {}\".format(participant_num, idx+1, j+1)\n",
    "\n",
    "        absolute_trial_index += n_trials\n",
    "\n",
    "    #Save MEG data\n",
    "    np.save(f\"/Users/mishaal/personalproj/clarion_replay/data/test_data/s{participant_num}/meg_data.npy\", meg_signal_data)\n",
    "    #save classifier data\n",
    "    np.save(f\"/Users/mishaal/personalproj/clarion_replay/data/test_data/s{participant_num}/classifier_data.npy\", [betas, intercepts])    \n",
    "    assert np.all(meg_correct_dup == np.ndarray(p_df[\"Correct\"])), \"correctness mismatch for participant %d\" % participant_num \n",
    "\n",
    "    p_df = pd.DataFrame(p_df)\n",
    "    p_df.to_csv(f\"/Users/mishaal/personalproj/clarion_replay/data/test_data/s{participant_num}/test_data.csv\")\n",
    "\n",
    "    return p_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6, 48)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_train_data_perparticipant(participant_num):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tapnseek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
