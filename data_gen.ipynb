{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TEST_GRIDS = {}\n",
    "ALL_TRAIN_GRIDS = {}\n",
    "\n",
    "\n",
    "def read_h5py_string(dataset):\n",
    "    refs = dataset[()][0]  # Unpack the array of object references\n",
    "    strings = []\n",
    "    for ref in refs:\n",
    "        obj = dataset.file[ref]\n",
    "        string = obj[()].tobytes().decode(\"utf-16\")  # Decode the byte string\n",
    "        strings.append(string)\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data_perparticipant(participant_num):\n",
    "    session_files = sorted(\n",
    "        glob.glob(\n",
    "            f\"/Users/mishaal/personalproj/clarion_replay/raw/Behav/s{participant_num}/T*.mat\"\n",
    "        )\n",
    "    )\n",
    "    num_sessions = len(session_files)\n",
    "    meg_data = h5py.File(\n",
    "        f\"/Users/mishaal/personalproj/clarion_replay/raw/data/s{participant_num}/Data_inference.mat\"\n",
    "    )\n",
    "    classifier_data = h5py.File(\n",
    "        f\"/Users/mishaal/personalproj/clarion_replay/raw/data/s{participant_num}/Class_data.mat\"\n",
    "    )\n",
    "\n",
    "    meg_signal_data = np.transpose(meg_data[\"data\"], (2, 1, 0))\n",
    "    meg_correct_dup = np.array(meg_data[\"correct_trials_all\"]).T\n",
    "\n",
    "    no_detect_grids = False\n",
    "\n",
    "    try:\n",
    "        bricks_conn_trial = np.array(meg_data[\"bricks_conn_trial\"]).T\n",
    "        bricks_rel_trial = np.array(meg_data[\"bricks_rel_trial\"]).T\n",
    "    except:\n",
    "        no_detect_grids = True\n",
    "\n",
    "    stim_labels = read_h5py_string(\n",
    "        meg_data[\"stimlabel\"]\n",
    "    )  # each unique presentation of a grid is given a label\n",
    "\n",
    "    assert num_sessions * 48 == len(stim_labels), (\n",
    "        f\"mismatch in trial numbers for participant {participant_num} {num_sessions * 48} {bricks_conn_trial.shape[0]}\"\n",
    "    )\n",
    "    # load the binomial classifiers\n",
    "    betas = np.array(classifier_data[\"betas_loc\"]).T\n",
    "    intercepts = np.array(classifier_data[\"intercepts_loc\"]).T\n",
    "\n",
    "    os.makedirs(\n",
    "        f\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/s{participant_num}\",\n",
    "        exist_ok=True,\n",
    "    )\n",
    "    os.makedirs(\n",
    "        f\"/Users/mishaal/personalproj/clarion_replay/processed/train_data/s{participant_num}\",\n",
    "        exist_ok=True,\n",
    "    )\n",
    "\n",
    "    p_df = {\n",
    "        \"PID\": [int(participant_num)] * len(stim_labels),\n",
    "        \"Session\": [],\n",
    "        \"Trial\": [],\n",
    "        \"Grid_Name\": [],\n",
    "        \"left_element\": [],\n",
    "        \"ontop_element\": [],\n",
    "        \"right_element\": [],\n",
    "        \"below_element\": [],\n",
    "        \"besideness\": [],\n",
    "        \"middle\": [],\n",
    "        \"ontopness\": [],\n",
    "        \"Q_Brick_Middle\": [],\n",
    "        \"Q_Brick_Left\": [],\n",
    "        \"Q_Relation\": [],\n",
    "        \"True Relation\": [],\n",
    "        \"Correct\": [],\n",
    "        \"RT\": [],\n",
    "    }\n",
    "\n",
    "    absolute_trial_index = 0\n",
    "    for idx, filename in enumerate(session_files):\n",
    "        all_data = loadmat(filename)\n",
    "        behav_data = all_data[\"res\"][0, 0][\"behav\"][0, 0]\n",
    "        stimulus_grids = behav_data[\"SOLUTIONS_BUILT\"]\n",
    "        correctness = behav_data[\"correct\"]\n",
    "        rts = behav_data[\"rt\"]\n",
    "        q_stimuli = behav_data[\"stim_catch\"]\n",
    "        query_relation = behav_data[\n",
    "            \"question_catch\"\n",
    "        ]  # a brick is presented in the middle and another on the top left corner. the relation of the top left brick to the middle brick is asked. This is the identity of the brick in the top left corner\n",
    "        true_relation = behav_data[\"relation_catch\"]  # the relation in question\n",
    "\n",
    "        # save experiment data\n",
    "        n_trials = correctness.shape[1]\n",
    "        p_df[\"Session\"].extend([idx + 1] * n_trials)\n",
    "        p_df[\"Trial\"].extend(list(range(1, n_trials + 1)))\n",
    "        # turns out labeling not unique?\n",
    "        stim_label = stim_labels[absolute_trial_index : absolute_trial_index + n_trials]\n",
    "        # p_df[\"Grid_Name\"].extend(stim_label)\n",
    "\n",
    "        if not no_detect_grids:\n",
    "            p_df[\"left_element\"].extend(\n",
    "                [\n",
    "                    bricks_rel_trial[i, 0]\n",
    "                    for i in range(\n",
    "                        absolute_trial_index, absolute_trial_index + n_trials\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            p_df[\"ontop_element\"].extend(\n",
    "                [\n",
    "                    bricks_rel_trial[i, 1]\n",
    "                    for i in range(\n",
    "                        absolute_trial_index, absolute_trial_index + n_trials\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            p_df[\"right_element\"].extend(\n",
    "                [\n",
    "                    bricks_rel_trial[i, 2]\n",
    "                    for i in range(\n",
    "                        absolute_trial_index, absolute_trial_index + n_trials\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            p_df[\"below_element\"].extend(\n",
    "                [\n",
    "                    bricks_rel_trial[i, 3]\n",
    "                    for i in range(\n",
    "                        absolute_trial_index, absolute_trial_index + n_trials\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            p_df[\"besideness\"].extend(\n",
    "                [\n",
    "                    bricks_conn_trial[i, 0]\n",
    "                    for i in range(\n",
    "                        absolute_trial_index, absolute_trial_index + n_trials\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            p_df[\"middle\"].extend(\n",
    "                [\n",
    "                    bricks_conn_trial[i, 1]\n",
    "                    for i in range(\n",
    "                        absolute_trial_index, absolute_trial_index + n_trials\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            p_df[\"ontopness\"].extend(\n",
    "                [\n",
    "                    bricks_conn_trial[i, 2]\n",
    "                    for i in range(\n",
    "                        absolute_trial_index, absolute_trial_index + n_trials\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        p_df[\"Q_Brick_Left\"].extend(q_stimuli[:, 0].flatten())\n",
    "        p_df[\"Q_Brick_Middle\"].extend(q_stimuli[:, 1].flatten())\n",
    "        p_df[\"Q_Relation\"].extend(\n",
    "            query_relation.flatten()\n",
    "        )  # the queried position of left in relation to the middle\n",
    "        p_df[\"True Relation\"].extend(\n",
    "            true_relation.flatten()\n",
    "        )  # the true position of left in relation to the middle\n",
    "\n",
    "        p_df[\"Correct\"].extend(correctness.flatten())\n",
    "        p_df[\"RT\"].extend(rts.flatten())\n",
    "\n",
    "        for j in range(n_trials):  # add the grid\n",
    "            t = 0\n",
    "            for grid in ALL_TEST_GRIDS:\n",
    "                if np.all(ALL_TEST_GRIDS[grid] == stimulus_grids[:, :, j]):\n",
    "                    t = 1\n",
    "                    p_df[\"Grid_Name\"].append(grid)\n",
    "                    break\n",
    "            if t == 0:\n",
    "                ALL_TEST_GRIDS[f\"GRID{len(ALL_TEST_GRIDS)}\"] = stimulus_grids[:, :, j]\n",
    "                p_df[\"Grid_Name\"].append(f\"GRID{len(ALL_TEST_GRIDS) - 1}\")\n",
    "\n",
    "            if no_detect_grids:\n",
    "                bricks_conn_trial, bricks_rel_trial = brick_connectedness(\n",
    "                    stimulus_grids[:, :, j]\n",
    "                )\n",
    "\n",
    "                p_df[\"left_element\"].append(bricks_rel_trial[0])\n",
    "                p_df[\"ontop_element\"].append(bricks_rel_trial[1])\n",
    "                p_df[\"right_element\"].append(bricks_rel_trial[2])\n",
    "                p_df[\"below_element\"].append(bricks_rel_trial[3])\n",
    "\n",
    "                p_df[\"besideness\"].append(bricks_conn_trial[0])\n",
    "                p_df[\"middle\"].append(bricks_conn_trial[1])\n",
    "                p_df[\"ontopness\"].append(bricks_conn_trial[2])\n",
    "\n",
    "            # else: # sanity checking\n",
    "            #     bricks_conn_trial_, bricks_rel_trial_ = brick_connectedness(stimulus_grids[:, :, j])\n",
    "            #     assert np.all(bricks_conn_trial[absolute_trial_index + j] == bricks_conn_trial_), f\"brick_conn_trial mismatch for participant {participant_num} session {idx+1} trial {j+1}\"\n",
    "            #     assert np.all(bricks_rel_trial[absolute_trial_index + j] == bricks_rel_trial_), f\"brick_rel_trial mismatch for participant {participant_num} session {idx+1} trial {j+1}\"\n",
    "\n",
    "        # if indeed grids were uniquely named:\n",
    "        # for j in range(n_trials):\n",
    "        #     grid_name = p_df[\"Grid_Name\"][absolute_trial_index + j]\n",
    "        #     if grid_name not in ALL_TEST_GRIDS:\n",
    "        #         ALL_TEST_GRIDS[grid_name] = [stimulus_grids[:, :, j], bricks_rel_trial[absolute_trial_index + j], bricks_conn_trial[absolute_trial_index + j]]\n",
    "        #     else:\n",
    "        #         assert np.all(ALL_TEST_GRIDS[grid_name] == stimulus_grids[:, :, j]), f\"grid mismatch for participant {participant_num} session {idx+1} trial {j+1}\"\n",
    "\n",
    "        absolute_trial_index += n_trials\n",
    "\n",
    "    # Save MEG data\n",
    "    np.save(\n",
    "        f\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/s{participant_num}/meg_data.npy\",\n",
    "        meg_signal_data,\n",
    "    )\n",
    "    # save classifier data\n",
    "    np.save(\n",
    "        f\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/s{participant_num}/classifier_coeffs.npy\",\n",
    "        betas,\n",
    "    )\n",
    "    np.save(\n",
    "        f\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/s{participant_num}/classifier_intercepts.npy\",\n",
    "        intercepts,\n",
    "    )\n",
    "    assert np.all(meg_correct_dup.flatten() == np.array(p_df[\"Correct\"])), (\n",
    "        f\"correctness mismatch for participant {participant_num}\"\n",
    "    )\n",
    "\n",
    "    p_df = pd.DataFrame(p_df)\n",
    "    p_df.to_csv(\n",
    "        f\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/s{participant_num}/test_data.csv\"\n",
    "    )\n",
    "\n",
    "    return p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5648668697a41488ae8ae32aa8b00c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "participants = glob.glob(\"/Users/mishaal/personalproj/clarion_replay/raw/Behav/s*\")\n",
    "participants = sorted([(p.split(\"/\")[-1][1:]) for p in participants])\n",
    "dfs = []\n",
    "for p in tqdm(participants):\n",
    "    if \"18\" in p:\n",
    "        continue\n",
    "    p_df = load_test_data_perparticipant(p)\n",
    "    dfs.append(p_df)\n",
    "\n",
    "# concatenate dataframes\n",
    "pd.concat(dfs).to_csv(\n",
    "    \"/Users/mishaal/personalproj/clarion_replay/processed/test_data/all_test_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_construction_data_participant(participant_num):\n",
    "    session_files = sorted(\n",
    "        glob.glob(\n",
    "            f\"/Users/mishaal/personalproj/clarion_replay/raw/Behav/Training_MEG/s{participant_num}/T*.mat\"\n",
    "        )\n",
    "    )\n",
    "    num_sessions = len(session_files)\n",
    "\n",
    "    p_df = {\"PID\": [], \"Session\": [], \"Trial\": [], \"Grid_Name\": []}\n",
    "\n",
    "    for idx, filename in enumerate(session_files):\n",
    "        all_data = loadmat(filename)\n",
    "        behav_data = all_data[\"res_train\"][0, 0]\n",
    "        stimulus_grids = behav_data[\"INFO_FORM\"]\n",
    "        correctness = behav_data[\"correct\"]\n",
    "\n",
    "        n_trials = correctness.shape[1]\n",
    "        p_df[\"Session\"].extend([idx + 1] * n_trials)\n",
    "        p_df[\"Trial\"].extend(list(range(1, n_trials + 1)))\n",
    "        p_df[\"PID\"].extend([int(participant_num)] * n_trials)\n",
    "\n",
    "        for j in range(n_trials):\n",
    "            for grid in ALL_TRAIN_GRIDS:\n",
    "                if np.all(ALL_TRAIN_GRIDS[grid] == stimulus_grids[:, :, j]):\n",
    "                    p_df[\"Grid_Name\"].append(grid)\n",
    "                    break\n",
    "            else:\n",
    "                ALL_TRAIN_GRIDS[f\"GRID{len(ALL_TRAIN_GRIDS)}\"] = stimulus_grids[:, :, j]\n",
    "                p_df[\"Grid_Name\"].append(f\"GRID{len(ALL_TRAIN_GRIDS) - 1}\")\n",
    "\n",
    "    # write the csv\n",
    "    p_df = pd.DataFrame(p_df)\n",
    "    p_df.to_csv(\n",
    "        f\"/Users/mishaal/personalproj/clarion_replay/processed/train_data/s{participant_num}/train_data_constr.csv\"\n",
    "    )\n",
    "    return p_df\n",
    "\n",
    "\n",
    "def load_train_rel_data_participant(participant_num):\n",
    "    session_files = sorted(\n",
    "        glob.glob(\n",
    "            f\"/Users/mishaal/personalproj/clarion_replay/raw/Behav/Training_MEG/s{participant_num}/D*.mat\"\n",
    "        )\n",
    "    )\n",
    "    num_sessions = len(session_files)\n",
    "\n",
    "    p_df = {\"PID\": [], \"Session\": [], \"Trial\": [], \"Grid_Name\": []}\n",
    "\n",
    "    for idx, filename in enumerate(session_files):\n",
    "        all_data = loadmat(filename)\n",
    "        behav_data = all_data[\"res_train\"][0, 0]\n",
    "        stimulus_grids = behav_data[\"SOLUTIONS\"]\n",
    "\n",
    "        n_trials = stimulus_grids.shape[2]\n",
    "        p_df[\"Session\"].extend([idx + 1] * n_trials)\n",
    "        p_df[\"Trial\"].extend(list(range(1, n_trials + 1)))\n",
    "        p_df[\"PID\"].extend([int(participant_num)] * n_trials)\n",
    "\n",
    "        for j in range(n_trials):\n",
    "            for grid in ALL_TRAIN_GRIDS:\n",
    "                if np.all(ALL_TRAIN_GRIDS[grid] == stimulus_grids[:, :, j]):\n",
    "                    p_df[\"Grid_Name\"].append(grid)\n",
    "                    break\n",
    "            else:\n",
    "                ALL_TRAIN_GRIDS[f\"GRID{len(ALL_TRAIN_GRIDS)}\"] = stimulus_grids[:, :, j]\n",
    "                p_df[\"Grid_Name\"].append(f\"GRID{len(ALL_TRAIN_GRIDS) - 1}\")\n",
    "\n",
    "    # write the csv\n",
    "    p_df = pd.DataFrame(p_df)\n",
    "    p_df.to_csv(\n",
    "        f\"/Users/mishaal/personalproj/clarion_replay/processed/train_data/s{participant_num}/train_data_rel.csv\"\n",
    "    )\n",
    "    return p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751285bc7bc34225a0968b6f7623d7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "participants = glob.glob(\"/Users/mishaal/personalproj/clarion_replay/raw/Behav/s*\")\n",
    "participants = sorted([(p.split(\"/\")[-1][1:]) for p in participants])\n",
    "dfs = []\n",
    "for p in tqdm(participants):\n",
    "    if \"18\" in p:\n",
    "        continue\n",
    "    # p_df = load_train_construction_data_participant(p)\n",
    "    p_df = load_train_rel_data_participant(p)\n",
    "    dfs.append(p_df)\n",
    "\n",
    "# concatenate dataframes\n",
    "# pd.concat(dfs).to_csv(\"/Users/mishaal/personalproj/clarion_replay/processed/train_data/all_train_cons_data.csv\")\n",
    "pd.concat(dfs).to_csv(\n",
    "    \"/Users/mishaal/personalproj/clarion_replay/processed/train_data/all_train_rel_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472 48\n"
     ]
    }
   ],
   "source": [
    "print(len(ALL_TRAIN_GRIDS), len(ALL_TEST_GRIDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "dupls = []\n",
    "for grid in ALL_TRAIN_GRIDS:\n",
    "    for grid2 in ALL_TEST_GRIDS:\n",
    "        if np.all(ALL_TRAIN_GRIDS[grid] == ALL_TEST_GRIDS[grid2]):\n",
    "            n += 1\n",
    "            dupls.append(grid)\n",
    "            break\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grid in ALL_TRAIN_GRIDS:\n",
    "    if grid not in dupls:\n",
    "        # save grid\n",
    "        np.save(\n",
    "            f\"/Users/mishaal/personalproj/clarion_replay/processed/train_data/train_stims/{grid}.npy\",\n",
    "            ALL_TRAIN_GRIDS[grid],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grid in ALL_TEST_GRIDS:\n",
    "    np.save(\n",
    "        f\"/Users/mishaal/personalproj/clarion_replay/processed/test_data/test_stims/{grid}.npy\",\n",
    "        ALL_TEST_GRIDS[grid],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tapnseek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
